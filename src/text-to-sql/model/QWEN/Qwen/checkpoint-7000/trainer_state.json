{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.7333333333333334,
  "eval_steps": 500,
  "global_step": 7000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 2.642791986465454,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 1.8846,
      "step": 50
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.5234982371330261,
      "learning_rate": 3.960000000000001e-05,
      "loss": 0.2738,
      "step": 100
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3656403720378876,
      "learning_rate": 5.96e-05,
      "loss": 0.1403,
      "step": 150
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.30610981583595276,
      "learning_rate": 7.960000000000001e-05,
      "loss": 0.1316,
      "step": 200
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.3637757897377014,
      "learning_rate": 9.960000000000001e-05,
      "loss": 0.1244,
      "step": 250
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.26584941148757935,
      "learning_rate": 0.00011960000000000001,
      "loss": 0.1202,
      "step": 300
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 0.23183198273181915,
      "learning_rate": 0.0001396,
      "loss": 0.118,
      "step": 350
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 0.2121836394071579,
      "learning_rate": 0.0001596,
      "loss": 0.1166,
      "step": 400
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.17734397947788239,
      "learning_rate": 0.0001796,
      "loss": 0.1138,
      "step": 450
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.1783164143562317,
      "learning_rate": 0.0001996,
      "loss": 0.1129,
      "step": 500
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 0.1629796326160431,
      "learning_rate": 0.0001986,
      "loss": 0.1125,
      "step": 550
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.18714290857315063,
      "learning_rate": 0.0001971714285714286,
      "loss": 0.116,
      "step": 600
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 0.1433125138282776,
      "learning_rate": 0.00019574285714285715,
      "loss": 0.1135,
      "step": 650
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 0.13849732279777527,
      "learning_rate": 0.0001943142857142857,
      "loss": 0.1133,
      "step": 700
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.14539149403572083,
      "learning_rate": 0.0001928857142857143,
      "loss": 0.1125,
      "step": 750
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 0.11340570449829102,
      "learning_rate": 0.00019145714285714286,
      "loss": 0.1114,
      "step": 800
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 0.1273549348115921,
      "learning_rate": 0.00019002857142857144,
      "loss": 0.1115,
      "step": 850
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.12481597065925598,
      "learning_rate": 0.0001886,
      "loss": 0.1106,
      "step": 900
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 0.11518200486898422,
      "learning_rate": 0.00018717142857142856,
      "loss": 0.1139,
      "step": 950
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.12931303679943085,
      "learning_rate": 0.00018574285714285715,
      "loss": 0.1094,
      "step": 1000
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.1175726056098938,
      "learning_rate": 0.00018431428571428574,
      "loss": 0.1114,
      "step": 1050
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 0.10854294896125793,
      "learning_rate": 0.0001828857142857143,
      "loss": 0.1097,
      "step": 1100
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 0.11345396190881729,
      "learning_rate": 0.00018145714285714286,
      "loss": 0.1112,
      "step": 1150
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.13277781009674072,
      "learning_rate": 0.00018002857142857144,
      "loss": 0.1117,
      "step": 1200
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.10065006464719772,
      "learning_rate": 0.0001786,
      "loss": 0.1098,
      "step": 1250
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 0.10476867109537125,
      "learning_rate": 0.0001771714285714286,
      "loss": 0.1111,
      "step": 1300
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.12486078590154648,
      "learning_rate": 0.00017574285714285715,
      "loss": 0.1098,
      "step": 1350
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 0.11242110282182693,
      "learning_rate": 0.0001743142857142857,
      "loss": 0.1104,
      "step": 1400
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 0.12990356981754303,
      "learning_rate": 0.0001728857142857143,
      "loss": 0.11,
      "step": 1450
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.09985532611608505,
      "learning_rate": 0.00017145714285714286,
      "loss": 0.1092,
      "step": 1500
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 0.0969817191362381,
      "learning_rate": 0.00017002857142857142,
      "loss": 0.1088,
      "step": 1550
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 0.11640731990337372,
      "learning_rate": 0.0001686,
      "loss": 0.1093,
      "step": 1600
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.09151516109704971,
      "learning_rate": 0.0001671714285714286,
      "loss": 0.1098,
      "step": 1650
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 0.0998951718211174,
      "learning_rate": 0.00016574285714285715,
      "loss": 0.1099,
      "step": 1700
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 0.1029210314154625,
      "learning_rate": 0.00016431428571428574,
      "loss": 0.1109,
      "step": 1750
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.11390747129917145,
      "learning_rate": 0.0001628857142857143,
      "loss": 0.1089,
      "step": 1800
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 0.08989733457565308,
      "learning_rate": 0.00016145714285714286,
      "loss": 0.1078,
      "step": 1850
    },
    {
      "epoch": 1.0133333333333334,
      "grad_norm": 0.10657798498868942,
      "learning_rate": 0.00016002857142857145,
      "loss": 0.1096,
      "step": 1900
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.09741362184286118,
      "learning_rate": 0.0001586,
      "loss": 0.1088,
      "step": 1950
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 0.08944667130708694,
      "learning_rate": 0.00015717142857142857,
      "loss": 0.1078,
      "step": 2000
    },
    {
      "epoch": 1.0933333333333333,
      "grad_norm": 0.10844093561172485,
      "learning_rate": 0.00015574285714285715,
      "loss": 0.1096,
      "step": 2050
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.10349657386541367,
      "learning_rate": 0.0001543142857142857,
      "loss": 0.1079,
      "step": 2100
    },
    {
      "epoch": 1.1466666666666667,
      "grad_norm": 0.10064782947301865,
      "learning_rate": 0.0001528857142857143,
      "loss": 0.1084,
      "step": 2150
    },
    {
      "epoch": 1.1733333333333333,
      "grad_norm": 0.08699137717485428,
      "learning_rate": 0.0001514571428571429,
      "loss": 0.1099,
      "step": 2200
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.0957491546869278,
      "learning_rate": 0.00015002857142857142,
      "loss": 0.1099,
      "step": 2250
    },
    {
      "epoch": 1.2266666666666666,
      "grad_norm": 0.0894235372543335,
      "learning_rate": 0.0001486,
      "loss": 0.1079,
      "step": 2300
    },
    {
      "epoch": 1.2533333333333334,
      "grad_norm": 0.08312150835990906,
      "learning_rate": 0.0001471714285714286,
      "loss": 0.1083,
      "step": 2350
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.09498859196901321,
      "learning_rate": 0.00014574285714285715,
      "loss": 0.1087,
      "step": 2400
    },
    {
      "epoch": 1.3066666666666666,
      "grad_norm": 0.10667505115270615,
      "learning_rate": 0.00014431428571428571,
      "loss": 0.109,
      "step": 2450
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.0904167890548706,
      "learning_rate": 0.0001428857142857143,
      "loss": 0.1082,
      "step": 2500
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.09521205723285675,
      "learning_rate": 0.00014145714285714286,
      "loss": 0.1082,
      "step": 2550
    },
    {
      "epoch": 1.3866666666666667,
      "grad_norm": 0.10419660806655884,
      "learning_rate": 0.00014002857142857145,
      "loss": 0.1098,
      "step": 2600
    },
    {
      "epoch": 1.4133333333333333,
      "grad_norm": 0.10125285387039185,
      "learning_rate": 0.0001386,
      "loss": 0.108,
      "step": 2650
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.09502722322940826,
      "learning_rate": 0.00013717142857142857,
      "loss": 0.1074,
      "step": 2700
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 0.09977582842111588,
      "learning_rate": 0.00013574285714285715,
      "loss": 0.1085,
      "step": 2750
    },
    {
      "epoch": 1.4933333333333334,
      "grad_norm": 0.09284418821334839,
      "learning_rate": 0.00013431428571428571,
      "loss": 0.1083,
      "step": 2800
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.0863305926322937,
      "learning_rate": 0.0001328857142857143,
      "loss": 0.1086,
      "step": 2850
    },
    {
      "epoch": 1.5466666666666666,
      "grad_norm": 0.09109297394752502,
      "learning_rate": 0.00013145714285714286,
      "loss": 0.1092,
      "step": 2900
    },
    {
      "epoch": 1.5733333333333333,
      "grad_norm": 0.10056093335151672,
      "learning_rate": 0.00013002857142857142,
      "loss": 0.1063,
      "step": 2950
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.1049480140209198,
      "learning_rate": 0.0001286,
      "loss": 0.1068,
      "step": 3000
    },
    {
      "epoch": 1.6266666666666667,
      "grad_norm": 0.08962450176477432,
      "learning_rate": 0.0001271714285714286,
      "loss": 0.1078,
      "step": 3050
    },
    {
      "epoch": 1.6533333333333333,
      "grad_norm": 0.09850325435400009,
      "learning_rate": 0.00012574285714285713,
      "loss": 0.1085,
      "step": 3100
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.11222735047340393,
      "learning_rate": 0.00012431428571428572,
      "loss": 0.1087,
      "step": 3150
    },
    {
      "epoch": 1.7066666666666666,
      "grad_norm": 0.0912945494055748,
      "learning_rate": 0.0001228857142857143,
      "loss": 0.1069,
      "step": 3200
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 0.08920736610889435,
      "learning_rate": 0.00012145714285714286,
      "loss": 0.1077,
      "step": 3250
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.09777642786502838,
      "learning_rate": 0.00012002857142857142,
      "loss": 0.109,
      "step": 3300
    },
    {
      "epoch": 1.7866666666666666,
      "grad_norm": 0.08293356746435165,
      "learning_rate": 0.0001186,
      "loss": 0.1082,
      "step": 3350
    },
    {
      "epoch": 1.8133333333333335,
      "grad_norm": 0.09895937144756317,
      "learning_rate": 0.00011717142857142858,
      "loss": 0.1087,
      "step": 3400
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.0809679627418518,
      "learning_rate": 0.00011574285714285716,
      "loss": 0.1081,
      "step": 3450
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 0.09159489721059799,
      "learning_rate": 0.00011431428571428573,
      "loss": 0.1103,
      "step": 3500
    },
    {
      "epoch": 1.8933333333333333,
      "grad_norm": 0.11553329974412918,
      "learning_rate": 0.00011288571428571429,
      "loss": 0.1091,
      "step": 3550
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.08731146901845932,
      "learning_rate": 0.00011145714285714286,
      "loss": 0.1066,
      "step": 3600
    },
    {
      "epoch": 1.9466666666666668,
      "grad_norm": 0.10101138800382614,
      "learning_rate": 0.00011002857142857144,
      "loss": 0.1083,
      "step": 3650
    },
    {
      "epoch": 1.9733333333333334,
      "grad_norm": 0.08639448881149292,
      "learning_rate": 0.00010860000000000001,
      "loss": 0.1081,
      "step": 3700
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.09237787872552872,
      "learning_rate": 0.00010717142857142857,
      "loss": 0.1085,
      "step": 3750
    },
    {
      "epoch": 2.026666666666667,
      "grad_norm": 0.08470236510038376,
      "learning_rate": 0.00010574285714285714,
      "loss": 0.1071,
      "step": 3800
    },
    {
      "epoch": 2.0533333333333332,
      "grad_norm": 0.0955241471529007,
      "learning_rate": 0.00010431428571428572,
      "loss": 0.1068,
      "step": 3850
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.0968659445643425,
      "learning_rate": 0.00010288571428571429,
      "loss": 0.1099,
      "step": 3900
    },
    {
      "epoch": 2.1066666666666665,
      "grad_norm": 0.09445925801992416,
      "learning_rate": 0.00010145714285714288,
      "loss": 0.1082,
      "step": 3950
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 0.07993841916322708,
      "learning_rate": 0.00010002857142857142,
      "loss": 0.1065,
      "step": 4000
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.09101805090904236,
      "learning_rate": 9.86e-05,
      "loss": 0.107,
      "step": 4050
    },
    {
      "epoch": 2.1866666666666665,
      "grad_norm": 0.07986748963594437,
      "learning_rate": 9.717142857142858e-05,
      "loss": 0.1082,
      "step": 4100
    },
    {
      "epoch": 2.2133333333333334,
      "grad_norm": 0.08501951396465302,
      "learning_rate": 9.574285714285714e-05,
      "loss": 0.1061,
      "step": 4150
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.08721504360437393,
      "learning_rate": 9.431428571428572e-05,
      "loss": 0.1074,
      "step": 4200
    },
    {
      "epoch": 2.2666666666666666,
      "grad_norm": 0.11352001130580902,
      "learning_rate": 9.288571428571429e-05,
      "loss": 0.1063,
      "step": 4250
    },
    {
      "epoch": 2.2933333333333334,
      "grad_norm": 0.09099381417036057,
      "learning_rate": 9.145714285714287e-05,
      "loss": 0.1086,
      "step": 4300
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.08699888736009598,
      "learning_rate": 9.002857142857143e-05,
      "loss": 0.1068,
      "step": 4350
    },
    {
      "epoch": 2.3466666666666667,
      "grad_norm": 0.07765808701515198,
      "learning_rate": 8.86e-05,
      "loss": 0.1072,
      "step": 4400
    },
    {
      "epoch": 2.3733333333333335,
      "grad_norm": 0.09617743641138077,
      "learning_rate": 8.717142857142857e-05,
      "loss": 0.1083,
      "step": 4450
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.08487937599420547,
      "learning_rate": 8.574285714285715e-05,
      "loss": 0.1059,
      "step": 4500
    },
    {
      "epoch": 2.4266666666666667,
      "grad_norm": 0.09303797036409378,
      "learning_rate": 8.431428571428572e-05,
      "loss": 0.1077,
      "step": 4550
    },
    {
      "epoch": 2.453333333333333,
      "grad_norm": 0.09237857908010483,
      "learning_rate": 8.288571428571429e-05,
      "loss": 0.1095,
      "step": 4600
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.09114684909582138,
      "learning_rate": 8.145714285714287e-05,
      "loss": 0.1076,
      "step": 4650
    },
    {
      "epoch": 2.506666666666667,
      "grad_norm": 0.08811494708061218,
      "learning_rate": 8.002857142857143e-05,
      "loss": 0.1058,
      "step": 4700
    },
    {
      "epoch": 2.533333333333333,
      "grad_norm": 0.0711018294095993,
      "learning_rate": 7.860000000000001e-05,
      "loss": 0.1074,
      "step": 4750
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.07968946546316147,
      "learning_rate": 7.717142857142857e-05,
      "loss": 0.1071,
      "step": 4800
    },
    {
      "epoch": 2.586666666666667,
      "grad_norm": 0.08921099454164505,
      "learning_rate": 7.574285714285715e-05,
      "loss": 0.107,
      "step": 4850
    },
    {
      "epoch": 2.6133333333333333,
      "grad_norm": 0.10874949395656586,
      "learning_rate": 7.431428571428572e-05,
      "loss": 0.1066,
      "step": 4900
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.09509328007698059,
      "learning_rate": 7.28857142857143e-05,
      "loss": 0.107,
      "step": 4950
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.09543206542730331,
      "learning_rate": 7.145714285714285e-05,
      "loss": 0.1083,
      "step": 5000
    },
    {
      "epoch": 2.6933333333333334,
      "grad_norm": 0.09286806732416153,
      "learning_rate": 7.002857142857143e-05,
      "loss": 0.11,
      "step": 5050
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.09808123111724854,
      "learning_rate": 6.860000000000001e-05,
      "loss": 0.106,
      "step": 5100
    },
    {
      "epoch": 2.7466666666666666,
      "grad_norm": 0.08343224227428436,
      "learning_rate": 6.717142857142857e-05,
      "loss": 0.1075,
      "step": 5150
    },
    {
      "epoch": 2.7733333333333334,
      "grad_norm": 0.08484739810228348,
      "learning_rate": 6.574285714285715e-05,
      "loss": 0.1066,
      "step": 5200
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.07823128998279572,
      "learning_rate": 6.431428571428572e-05,
      "loss": 0.1078,
      "step": 5250
    },
    {
      "epoch": 2.8266666666666667,
      "grad_norm": 0.08280842751264572,
      "learning_rate": 6.28857142857143e-05,
      "loss": 0.1074,
      "step": 5300
    },
    {
      "epoch": 2.8533333333333335,
      "grad_norm": 0.10104429721832275,
      "learning_rate": 6.145714285714285e-05,
      "loss": 0.1068,
      "step": 5350
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.0882638469338417,
      "learning_rate": 6.0028571428571435e-05,
      "loss": 0.1078,
      "step": 5400
    },
    {
      "epoch": 2.9066666666666667,
      "grad_norm": 0.08214523643255234,
      "learning_rate": 5.86e-05,
      "loss": 0.1069,
      "step": 5450
    },
    {
      "epoch": 2.9333333333333336,
      "grad_norm": 0.08653835952281952,
      "learning_rate": 5.7171428571428575e-05,
      "loss": 0.1065,
      "step": 5500
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.08249503374099731,
      "learning_rate": 5.574285714285714e-05,
      "loss": 0.1072,
      "step": 5550
    },
    {
      "epoch": 2.986666666666667,
      "grad_norm": 0.08991768956184387,
      "learning_rate": 5.4314285714285715e-05,
      "loss": 0.1073,
      "step": 5600
    },
    {
      "epoch": 3.013333333333333,
      "grad_norm": 0.08782804012298584,
      "learning_rate": 5.288571428571428e-05,
      "loss": 0.105,
      "step": 5650
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.08807040750980377,
      "learning_rate": 5.145714285714286e-05,
      "loss": 0.1088,
      "step": 5700
    },
    {
      "epoch": 3.066666666666667,
      "grad_norm": 0.09337668865919113,
      "learning_rate": 5.0028571428571436e-05,
      "loss": 0.1072,
      "step": 5750
    },
    {
      "epoch": 3.0933333333333333,
      "grad_norm": 0.09887755662202835,
      "learning_rate": 4.86e-05,
      "loss": 0.1083,
      "step": 5800
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.10104574263095856,
      "learning_rate": 4.717142857142857e-05,
      "loss": 0.1065,
      "step": 5850
    },
    {
      "epoch": 3.1466666666666665,
      "grad_norm": 0.11142000555992126,
      "learning_rate": 4.574285714285714e-05,
      "loss": 0.1077,
      "step": 5900
    },
    {
      "epoch": 3.1733333333333333,
      "grad_norm": 0.11710672825574875,
      "learning_rate": 4.4314285714285716e-05,
      "loss": 0.1062,
      "step": 5950
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.09823892265558243,
      "learning_rate": 4.288571428571429e-05,
      "loss": 0.1066,
      "step": 6000
    },
    {
      "epoch": 3.2266666666666666,
      "grad_norm": 0.09104139357805252,
      "learning_rate": 4.145714285714286e-05,
      "loss": 0.1059,
      "step": 6050
    },
    {
      "epoch": 3.2533333333333334,
      "grad_norm": 0.09268245100975037,
      "learning_rate": 4.002857142857143e-05,
      "loss": 0.1063,
      "step": 6100
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 0.08807871490716934,
      "learning_rate": 3.86e-05,
      "loss": 0.105,
      "step": 6150
    },
    {
      "epoch": 3.3066666666666666,
      "grad_norm": 0.08834454417228699,
      "learning_rate": 3.717142857142858e-05,
      "loss": 0.1061,
      "step": 6200
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.08110859990119934,
      "learning_rate": 3.574285714285714e-05,
      "loss": 0.108,
      "step": 6250
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.08913280814886093,
      "learning_rate": 3.431428571428572e-05,
      "loss": 0.1055,
      "step": 6300
    },
    {
      "epoch": 3.3866666666666667,
      "grad_norm": 0.10605811327695847,
      "learning_rate": 3.2885714285714284e-05,
      "loss": 0.1068,
      "step": 6350
    },
    {
      "epoch": 3.413333333333333,
      "grad_norm": 0.0887269526720047,
      "learning_rate": 3.145714285714286e-05,
      "loss": 0.1066,
      "step": 6400
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.07946690917015076,
      "learning_rate": 3.0028571428571427e-05,
      "loss": 0.1054,
      "step": 6450
    },
    {
      "epoch": 3.466666666666667,
      "grad_norm": 0.08393499255180359,
      "learning_rate": 2.86e-05,
      "loss": 0.1055,
      "step": 6500
    },
    {
      "epoch": 3.493333333333333,
      "grad_norm": 0.07692655175924301,
      "learning_rate": 2.7171428571428574e-05,
      "loss": 0.107,
      "step": 6550
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.10639262944459915,
      "learning_rate": 2.5742857142857148e-05,
      "loss": 0.1063,
      "step": 6600
    },
    {
      "epoch": 3.546666666666667,
      "grad_norm": 0.09338385611772537,
      "learning_rate": 2.4314285714285714e-05,
      "loss": 0.1074,
      "step": 6650
    },
    {
      "epoch": 3.5733333333333333,
      "grad_norm": 0.09806262701749802,
      "learning_rate": 2.2885714285714288e-05,
      "loss": 0.1057,
      "step": 6700
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.08279877156019211,
      "learning_rate": 2.1457142857142858e-05,
      "loss": 0.1064,
      "step": 6750
    },
    {
      "epoch": 3.626666666666667,
      "grad_norm": 0.08992147445678711,
      "learning_rate": 2.002857142857143e-05,
      "loss": 0.1059,
      "step": 6800
    },
    {
      "epoch": 3.6533333333333333,
      "grad_norm": 0.09372809529304504,
      "learning_rate": 1.86e-05,
      "loss": 0.1055,
      "step": 6850
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.08617834746837616,
      "learning_rate": 1.717142857142857e-05,
      "loss": 0.1059,
      "step": 6900
    },
    {
      "epoch": 3.7066666666666666,
      "grad_norm": 0.09038549661636353,
      "learning_rate": 1.574285714285714e-05,
      "loss": 0.1063,
      "step": 6950
    },
    {
      "epoch": 3.7333333333333334,
      "grad_norm": 0.09429702162742615,
      "learning_rate": 1.4314285714285717e-05,
      "loss": 0.107,
      "step": 7000
    }
  ],
  "logging_steps": 50,
  "max_steps": 7500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.308350132224e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
